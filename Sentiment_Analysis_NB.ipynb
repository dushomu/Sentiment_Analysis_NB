{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Sentiment Analysis using Naive Bayes Classifier"
      ],
      "metadata": {
        "id": "UCJmqqJOgLsw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Introduction\n",
        "\n",
        "- This project builds a **sentiment analysis model** that classifies restaurant reviews as **positive or negative** using a **Naive Bayes (NB) classifier**. Despite its simplicity, NB performs well for sentiment analysis, especially on **smaller datasets**, and is widely used as a **baseline model**.\n",
        "\n",
        "- **Dataset**:\n",
        "  - We use a **public Kaggle dataset** of **1,000 restaurant reviews**.\n",
        "  - The data is perfectly balanced. Each review is a short text paired with a sentiment label, making the dataset ideal for training a binary classifier."
      ],
      "metadata": {
        "id": "zp7pTTgDtLdD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Import Libraries and Load Dataset"
      ],
      "metadata": {
        "id": "idlZBYIbgXc3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv('data/Restaurant_Reviews.tsv', sep='\\t')\n",
        "\n",
        "print(\"Number of reviews:\", df.shape[0])\n",
        "print(df.head(5))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-FErnHmWib3",
        "outputId": "499a20d8-6a56-4872-deac-ad9d15cdca12"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of reviews: 1000\n",
            "                                              Review  Liked\n",
            "0                           Wow... Loved this place.      1\n",
            "1                                 Crust is not good.      0\n",
            "2          Not tasty and the texture was just nasty.      0\n",
            "3  Stopped by during the late May bank holiday of...      1\n",
            "4  The selection on the menu was great and so wer...      1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Liked'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eF35Rqd5rddu",
        "outputId": "8b2054bc-d72b-4708-f40c-bffea448d747"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Liked\n",
              "1    500\n",
              "0    500\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Text Preprocessing"
      ],
      "metadata": {
        "id": "o0G3SxQHggB-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Download NLTK resources (run once)\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Initialize stopwords and lemmatizer\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def preprocess_text(text: str) -> str:\n",
        "    # Remove all non-letter characters\n",
        "    text = re.sub(r'[^A-Za-z]', ' ', text)\n",
        "    # Convert to lowercase and tokenize\n",
        "    tokens = text.lower().split()\n",
        "    # Remove stopwords\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "    # Lemmatize each word to its root form\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "    # Join tokens back into a single string\n",
        "    return ' '.join(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPKNvYMeWifL",
        "outputId": "fe63fdbc-de95-4f4b-b78f-72433142dc5b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess all reviews in the dataset\n",
        "corpus = [preprocess_text(review) for review in df['Review']]\n",
        "\n",
        "print(\"Original review:\", df['Review'][0])\n",
        "print(\"After preprocessing:\", corpus[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFXvpli5glAT",
        "outputId": "f14a5012-42cb-4e24-daa9-570cffccd83f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original review: Wow... Loved this place.\n",
            "After preprocessing: wow loved place\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Feature Extraction (Bag-of-Words Model)"
      ],
      "metadata": {
        "id": "ImVNvCsegtaF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Initialize CountVectorizer to convert text to feature vectors\n",
        "vectorizer = CountVectorizer()\n",
        "# learn vocabulary and transform corpus\n",
        "X_features = vectorizer.fit_transform(corpus)\n",
        "\n",
        "print(\"Number of features (vocabulary size):\", len(vectorizer.get_feature_names_out()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RaBXm1RjWiiC",
        "outputId": "23f9f895-a25d-43fc-cd89-c14305809f06"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of features (vocabulary size): 1766\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Train/Test Split"
      ],
      "metadata": {
        "id": "dVV8OQrTrwdl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# feature matrix\n",
        "X = X_features\n",
        "# sentiment labels array\n",
        "y = df['Liked'].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "print(\"Training examples:\", X_train.shape[0])\n",
        "print(\"Testing examples:\", X_test.shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylH9cbUHWik1",
        "outputId": "9b18028f-1dce-48fd-f1d5-f77ff961560b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training examples: 800\n",
            "Testing examples: 200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Training the Naive Bayes Classifier"
      ],
      "metadata": {
        "id": "XYavnwMSr9XM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "nb_classifier = MultinomialNB()\n",
        "\n",
        "# Train (fit) the model on the training data\n",
        "nb_classifier.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "NpIfDMXrWins",
        "outputId": "47e9844f-4ad8-4f2a-9775-aee16500da5b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Model Evaluation"
      ],
      "metadata": {
        "id": "rXUAXzf5hEMZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Predict sentiments for the test set\n",
        "y_pred = nb_classifier.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Test Accuracy: {accuracy*100:.2f}%\")\n",
        "\n",
        "# Display detailed classification report (precision, recall, f1-score)\n",
        "print(classification_report(y_test, y_pred, target_names=[\"Negative\", \"Positive\"]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxTizAVmZgSN",
        "outputId": "2b4f7431-da42-4440-a28a-a021a3033806"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 74.50%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.73      0.74      0.74        96\n",
            "    Positive       0.76      0.75      0.75       104\n",
            "\n",
            "    accuracy                           0.74       200\n",
            "   macro avg       0.74      0.74      0.74       200\n",
            "weighted avg       0.75      0.74      0.75       200\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Testing the Model on New Reviews"
      ],
      "metadata": {
        "id": "hPKz0rrwsWJW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sentiment(review: str):\n",
        "    cleaned = preprocess_text(review)\n",
        "    features = vectorizer.transform([cleaned])\n",
        "    pred = nb_classifier.predict(features)\n",
        "    return \"Positive\" if pred[0] == 1 else \"Negative\"\n",
        "\n",
        "print(predict_sentiment(\"The food was absolutely wonderful, fresh and very tasty!\"))\n",
        "print(predict_sentiment(\"I will never come to this restaurant again. The service was terrible.\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Im9cUfVgsYx6",
        "outputId": "bcc4ce81-f159-4023-f2dc-fce96a429b17"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive\n",
            "Negative\n"
          ]
        }
      ]
    }
  ]
}